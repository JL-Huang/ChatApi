version: '3.8'

services:
  # Flask 服务
  chat-api:
    image: huangjingliang/chat-api:latest  # 从 Docker Hub 拉取最新镜像
    container_name: chat-api-container
    ports:
      - "5000:5000"
    environment:
      - MODEL_NAME=deepseek-llm  # 环境变量，可以在 Flask 服务中访问
    restart: always
    depends_on:
      - ollama  # Flask 服务依赖 Ollama 服务

  # Ollama 服务
  ollama:
    image: ollama/ollama:latest   # 从 Docker Hub 拉取最新镜像
    container_name: ollama
    ports:
      - "11434:11434"  # Ollama 服务端口
    volumes:
      - ~/.ollama:/root/.ollama  # 持久化数据
    restart: always

# 定义数据卷，用于持久化数据
volumes:
  ollama-data:
